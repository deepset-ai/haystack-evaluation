{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3066ab55-72ac-4669-b303-8482877149f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dsbatista/virtual_envs/haystack/lib/python3.9/site-packages/ddtrace/internal/module.py:220: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  self.loader.exec_module(module)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from haystack import Document\n",
    "\n",
    "base_path = \"datasets/SQuAD-2.0/transformed_squad/\"\n",
    "\n",
    "def load_transformed_squad():\n",
    "    with open(base_path+\"questions.jsonl\", \"r\") as f:\n",
    "        questions = [json.loads(x) for x in f.readlines()]\n",
    "    for idx, question in enumerate(questions):\n",
    "        question[\"query_id\"] = f\"query_{idx}\"\n",
    "\n",
    "    def create_document(text: str, name: str):\n",
    "        return Document(content=text, meta={\"name\": name})\n",
    "\n",
    "    documents = []\n",
    "    for root, dirs, files in os.walk(base_path+\"articles\"):\n",
    "        for article in files:\n",
    "            with open(f\"{root}/{article}\", \"r\") as f:\n",
    "                article_text = f.read()\n",
    "                documents.append(create_document(article_text, article.replace(\".txt\", \"\")))\n",
    "\n",
    "    return questions, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1912ab-4888-40cd-9839-633694a3fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.evaluators.document_recall import RecallMode\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "\n",
    "def indexing(documents, embedding_model, chunk_size):\n",
    "    document_store = InMemoryDocumentStore()\n",
    "    doc_splitter = DocumentSplitter(split_by=\"sentence\", split_length=chunk_size)\n",
    "    doc_writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
    "    doc_embedder = SentenceTransformersDocumentEmbedder(model=embedding_model)\n",
    "    ingestion_pipe = Pipeline()\n",
    "    ingestion_pipe.add_component(instance=doc_splitter, name=\"doc_splitter\")\n",
    "    ingestion_pipe.add_component(instance=doc_embedder, name=\"doc_embedder\")\n",
    "    ingestion_pipe.add_component(instance=doc_writer, name=\"doc_writer\")\n",
    "    ingestion_pipe.connect(\"doc_splitter.documents\", \"doc_embedder.documents\")\n",
    "    ingestion_pipe.connect(\"doc_embedder.documents\", \"doc_writer.documents\")\n",
    "    ingestion_pipe.run({\"doc_splitter\": {\"documents\": documents}})\n",
    "\n",
    "    return document_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79d6283-c639-474e-bb19-0be485ce1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from architectures.extractive_qa import get_extractive_qa_pipeline\n",
    "\n",
    "def run_extractive_qa(doc_store, questions, embedding_model, top_k_retriever):\n",
    "\n",
    "    extractive_qa = get_extractive_qa_pipeline(document_store=doc_store, embedding_model=embedding_model,top_k_retriever=top_k_retriever)\n",
    "\n",
    "    # predicted data\n",
    "    retrieved_docs = []\n",
    "    predicted_answers = []\n",
    "\n",
    "    for q in tqdm(questions):\n",
    "        response = extractive_qa.run(\n",
    "            data={\"embedder\": {\"text\": q}, \"retriever\": {\"top_k\": top_k_retriever}, \"reader\": {\"query\": q, \"top_k\": 1}}\n",
    "        )\n",
    "        retrieved_docs.append([answer.document for answer in response['reader']['answers']])\n",
    "        predicted_answers.append(response['reader']['answers'][0].data)\n",
    "\n",
    "    return retrieved_docs, predicted_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94eb3e19-273d-4467-aaa5-42371bd450af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.evaluators import (\n",
    "    AnswerExactMatchEvaluator,\n",
    "    DocumentMRREvaluator,\n",
    "    DocumentMAPEvaluator,\n",
    "    DocumentRecallEvaluator,\n",
    "    SASEvaluator,\n",
    ")\n",
    "\n",
    "from haystack.evaluation import EvaluationRunResult\n",
    "\n",
    "def run_evaluation(embedding_model, ground_truth_docs, retrieved_docs, questions, predicted_answers, ground_truth_answers):\n",
    "    eval_pipeline = Pipeline()\n",
    "    eval_pipeline.add_component(\"doc_mrr\", DocumentMRREvaluator())\n",
    "    eval_pipeline.add_component(\"doc_map\", DocumentMAPEvaluator())\n",
    "    eval_pipeline.add_component(\"doc_recall_single_hit\", DocumentRecallEvaluator(mode=RecallMode.SINGLE_HIT))\n",
    "    eval_pipeline.add_component(\"doc_recall_multi_hit\", DocumentRecallEvaluator(mode=RecallMode.MULTI_HIT))\n",
    "    eval_pipeline.add_component(\"answer_exact\", AnswerExactMatchEvaluator())\n",
    "    eval_pipeline.add_component(\"sas\", SASEvaluator(model=embedding_model))\n",
    "\n",
    "    # get the original documents from the retrieved documents which were split\n",
    "    original_retrieved_docs = []\n",
    "    for doc in retrieved_docs:\n",
    "        original_docs = []\n",
    "        for split_doc in doc:\n",
    "            for original_doc in ground_truth_docs:\n",
    "                if split_doc.meta[\"name\"] == original_doc[0].meta[\"name\"]:\n",
    "                    original_docs.append(original_doc[0])\n",
    "        original_retrieved_docs.append(original_docs)\n",
    "\n",
    "    eval_pipeline_results = eval_pipeline.run(\n",
    "        {\n",
    "            \"doc_mrr\": {\"ground_truth_documents\": ground_truth_docs, \"retrieved_documents\": original_retrieved_docs},\n",
    "            \"sas\": {\"predicted_answers\": predicted_answers, \"ground_truth_answers\": ground_truth_answers},\n",
    "            \"answer_exact\": {\"predicted_answers\": predicted_answers, \"ground_truth_answers\": ground_truth_answers},\n",
    "            \"doc_map\": {\"ground_truth_documents\": ground_truth_docs, \"retrieved_documents\": original_retrieved_docs},\n",
    "            \"doc_recall_single_hit\": {\"ground_truth_documents\": ground_truth_docs, \"retrieved_documents\": original_retrieved_docs},\n",
    "            \"doc_recall_multi_hit\": {\"ground_truth_documents\": ground_truth_docs, \"retrieved_documents\": original_retrieved_docs}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"doc_mrr\": eval_pipeline_results['doc_mrr'],\n",
    "        \"sas\": eval_pipeline_results['sas'],\n",
    "        \"doc_map\": eval_pipeline_results['doc_map'],\n",
    "        \"doc_recall_single_hit\": eval_pipeline_results['doc_recall_single_hit'],\n",
    "        \"doc_recall_multi_hit\": eval_pipeline_results['doc_recall_multi_hit']\n",
    "    }\n",
    "\n",
    "    inputs = {'questions': questions, 'true_answers': ground_truth_answers, 'predicted_answers': predicted_answers}\n",
    "\n",
    "    return results, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09fe1c8f-1345-43a5-a6c0-fd992eba29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def parameter_tuning(queries, documents):\n",
    "    \"\"\"\n",
    "    Run the basic RAG model with different parameters, and evaluate the results.\n",
    "\n",
    "    The parameters to be tuned are: embedding model, top_k, and chunk_size.\n",
    "    \"\"\"\n",
    "    embedding_models = {\n",
    "        \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        \"sentence-transformers/msmarco-distilroberta-base-v2\",\n",
    "        \"sentence-transformers/all-mpnet-base-v2\"\n",
    "    }\n",
    "    top_k_values = [1, 2, 3]\n",
    "    chunk_sizes = [5, 10, 15]\n",
    "\n",
    "    out_path = Path(\"squad_results_extractive_qa/\")\n",
    "    out_path.mkdir(exist_ok=True)\n",
    "\n",
    "    questions = []\n",
    "    ground_truth_answers = []\n",
    "    ground_truth_docs = []\n",
    "    for sample in queries:\n",
    "        questions.append(sample[\"question\"])\n",
    "        ground_truth_answers.append(sample[\"answers\"][\"text\"][0])\n",
    "        ground_truth_docs.append([doc for doc in documents if doc.meta[\"name\"] == sample[\"document\"]])\n",
    "\n",
    "    for embedding_model in embedding_models:\n",
    "        for top_k in top_k_values:\n",
    "            for chunk_size in chunk_sizes:\n",
    "                name_params = f\"{embedding_model.split('/')[-1]}__top_k:{top_k}__chunk_size:{chunk_size}\"\n",
    "                print(name_params)\n",
    "                print(\"Indexing documents\")\n",
    "                doc_store = indexing(documents, embedding_model, chunk_size)\n",
    "                print(\"Running RAG pipeline\")\n",
    "                retrieved_docs, predicted_answers = run_extractive_qa(doc_store, questions, embedding_model, top_k)\n",
    "                print(f\"Running evaluation\")\n",
    "                results, inputs = run_evaluation(\n",
    "                    embedding_model, ground_truth_docs, retrieved_docs, questions, predicted_answers,\n",
    "                    ground_truth_answers\n",
    "                )\n",
    "                eval_results = EvaluationRunResult(run_name=name_params, inputs=inputs, results=results)\n",
    "                eval_results.score_report().to_csv(f\"{out_path}/score_report_{name_params}.csv\")\n",
    "                eval_results.to_pandas().to_csv(f\"{out_path}/detailed_{name_params}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a3e456-de41-4fce-ad61-4acf8681be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "all_queries, documents = load_transformed_squad()\n",
    "queries = random.sample(all_queries, 100)  # take a sample of 100 questions\n",
    "parameter_tuning(queries, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3684c-7743-41a4-9bb7-a32ed526f9c1",
   "metadata": {},
   "source": [
    "## Let's analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f414b9d5-261b-430c-9307-a11fdb52b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_results(f_name: str):\n",
    "    pattern = r\"score_report_(.*?)__top_k:(\\d+)__chunk_size:(\\d+)\\.csv\"\n",
    "    match = re.search(pattern, f_name)\n",
    "    if match:\n",
    "        embeddings_model = match.group(1)\n",
    "        top_k = int(match.group(2))\n",
    "        chunk_size = int(match.group(3))\n",
    "        return embeddings_model, top_k, chunk_size\n",
    "    else:\n",
    "        print(\"No match found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd1c110-b3e2-42e3-a48c-71ac5c9dd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_scores(path: str):\n",
    "    all_scores = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f_name in files:\n",
    "            if not f_name.startswith(\"score_report\"):\n",
    "                continue\n",
    "    \n",
    "            embeddings_model, top_k, chunk_size = parse_results(f_name)\n",
    "    \n",
    "            df = pd.read_csv(path+\"/\"+f_name)\n",
    "    \n",
    "            df.rename(columns={'Unnamed: 0': 'metric'}, inplace=True)\n",
    "            df_transposed = df.T\n",
    "            df_transposed.columns = df_transposed.iloc[0]\n",
    "            df_transposed = df_transposed[1:]\n",
    "    \n",
    "            # Add new columns\n",
    "            df_transposed['embeddings'] = embeddings_model\n",
    "            df_transposed['top_k'] = top_k\n",
    "            df_transposed['chunk_size'] = chunk_size\n",
    "    \n",
    "            all_scores.append(df_transposed)\n",
    "    \n",
    "    df = pd.concat(all_scores)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5714699-25cc-4e82-b413-f3f6cdb11dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_scores('squad_results_extractive_qa/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65a0d81-b692-4e4d-8f40-70aecb209eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_mrr</th>\n",
       "      <th>sas</th>\n",
       "      <th>doc_map</th>\n",
       "      <th>doc_recall_single_hit</th>\n",
       "      <th>doc_recall_multi_hit</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>top_k</th>\n",
       "      <th>chunk_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.429623</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.478246</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.623278</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.695908</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.674235</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.629406</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.526742</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.702884</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65669</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.44841</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.479268</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.729105</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.622023</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.619113</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.588129</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.502602</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.526595</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>msmarco-distilroberta-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.738153</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.641659</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.540748</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65164</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.727557</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68523</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.694025</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_mrr       sas doc_map doc_recall_single_hit doc_recall_multi_hit  \\\n",
       "0     0.65  0.429623    0.65                  0.65                 0.65   \n",
       "1     0.61  0.430066    0.61                  0.61                 0.61   \n",
       "2     0.65  0.546312    0.65                  0.65                 0.65   \n",
       "3     0.68  0.478246    0.68                  0.68                 0.68   \n",
       "4     0.73  0.623278    0.73                  0.73                 0.73   \n",
       "5     0.78  0.695908    0.78                  0.78                 0.78   \n",
       "6     0.76  0.674235    0.76                  0.76                 0.76   \n",
       "7     0.73  0.629406    0.73                  0.73                 0.73   \n",
       "8     0.67  0.526742    0.67                  0.67                 0.67   \n",
       "9     0.74  0.702884    0.74                  0.74                 0.74   \n",
       "10    0.73   0.65669    0.73                  0.73                 0.73   \n",
       "11    0.63   0.44841    0.63                  0.63                 0.63   \n",
       "12    0.62  0.479268    0.62                  0.62                 0.62   \n",
       "13    0.75  0.729105    0.75                  0.75                 0.75   \n",
       "14    0.76  0.622023    0.76                  0.76                 0.76   \n",
       "15    0.73  0.619113    0.73                  0.73                 0.73   \n",
       "16    0.73  0.588129    0.73                  0.73                 0.73   \n",
       "17    0.66  0.502602    0.66                  0.66                 0.66   \n",
       "18    0.67  0.526595    0.67                  0.67                 0.67   \n",
       "19    0.76  0.621528    0.76                  0.76                 0.76   \n",
       "20    0.79  0.738153    0.79                  0.79                 0.79   \n",
       "21    0.74  0.641659    0.74                  0.74                 0.74   \n",
       "22    0.65  0.540748    0.65                  0.65                 0.65   \n",
       "23    0.79   0.65164    0.79                  0.79                 0.79   \n",
       "24    0.78  0.727557    0.78                  0.78                 0.78   \n",
       "25    0.79   0.68523    0.79                  0.79                 0.79   \n",
       "26    0.81  0.694025    0.81                  0.81                 0.81   \n",
       "\n",
       "                       embeddings  top_k  chunk_size  \n",
       "0   msmarco-distilroberta-base-v2      1           5  \n",
       "1   msmarco-distilroberta-base-v2      1          15  \n",
       "2   msmarco-distilroberta-base-v2      3           5  \n",
       "3   msmarco-distilroberta-base-v2      2          10  \n",
       "4               all-mpnet-base-v2      1          10  \n",
       "5               all-mpnet-base-v2      2          15  \n",
       "6                all-MiniLM-L6-v2      3          10  \n",
       "7               all-mpnet-base-v2      1          15  \n",
       "8   msmarco-distilroberta-base-v2      2           5  \n",
       "9               all-mpnet-base-v2      2          10  \n",
       "10               all-MiniLM-L6-v2      3          15  \n",
       "11  msmarco-distilroberta-base-v2      1          10  \n",
       "12  msmarco-distilroberta-base-v2      2          15  \n",
       "13              all-mpnet-base-v2      3          10  \n",
       "14              all-mpnet-base-v2      1           5  \n",
       "15               all-MiniLM-L6-v2      2          15  \n",
       "16               all-MiniLM-L6-v2      1          10  \n",
       "17  msmarco-distilroberta-base-v2      3          15  \n",
       "18  msmarco-distilroberta-base-v2      3          10  \n",
       "19               all-MiniLM-L6-v2      1           5  \n",
       "20              all-mpnet-base-v2      3          15  \n",
       "21               all-MiniLM-L6-v2      2          10  \n",
       "22               all-MiniLM-L6-v2      1          15  \n",
       "23               all-MiniLM-L6-v2      2           5  \n",
       "24              all-mpnet-base-v2      3           5  \n",
       "25               all-MiniLM-L6-v2      3           5  \n",
       "26              all-mpnet-base-v2      2           5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac305d9a-d714-462f-a5b9-d449271f5821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
